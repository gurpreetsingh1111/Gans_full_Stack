{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter-6 Microscopists Gans(Exploring GAN latent space to generate images with desired features​).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dataset from: Dataset from: https://susanqq.github.io/UTKFace/ \n",
        "Latent space is hard to interpret unless conditioned using many classes.​\n",
        "But, the latent space can be exploited using generated images.​\n",
        "Here is how...\n",
        "x Generate 10s of images using random latent vectors.​\n",
        "x Identify many images within each category of interest (e.g., smiling man, neutral man, etc. )​\n",
        "x Average the latent vectors for each category to get a mean representation in the latent space (for that category).​\n",
        "x Use these mean latent vectors to generate images with features of interest. ​\n",
        "This part of the code is used to train a GAN on 128x128x3 images.(e.g. Human Faces data)\n",
        "The generator model can then be used to generate new images. (new faces)\n",
        "The features in the new images can be 'engineered' by doing simple arithmetic\n",
        "between vectors that are used to generate images. \n",
        "In summary, you can find the latent vectors for Smiling Man, neutral face man, \n",
        "and a baby with neutral face and then generate a smiling baby face by:\n",
        "    Smiling Man + Neutral Man - Neutral baby = Smiling Baby\n",
        "\"\"\"\n",
        "\n",
        "# Import the required libraries\n",
        "from numpy import zeros, ones\n",
        "from numpy.random import randn, randint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# define the standalone discriminator model\n",
        "# Input would be 128x128x3 images and the output would be a binary (using sigmoid)\n",
        "#Remember that the discriminator is just a binary classifier for true/fake images.\n",
        "def define_discriminator(in_shape=(128,128,3)):\n",
        "\tmodel = Sequential()\n",
        "\t# normal\n",
        "\tmodel.add(Conv2D(128, (3,3), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 64x64\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 32x32\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 16x16\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 8x8\n",
        "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# classifier\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "#Verify the model summary\n",
        "test_discr = define_discriminator()\n",
        "print(test_discr.summary())\n",
        "plot_model(test_discr, to_file='disc_model.png', show_shapes=True)\n",
        "\n",
        "# define the standalone generator model\n",
        "# Generator must generate 128x128x3 images that can be fed into the discriminator. \n",
        "# So, we start with enough nodes in the dense layer that can be gradually upscaled\n",
        "#to 128x128x3. \n",
        "#Remember that the input would be a latent vector (usually size 100)\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# Define number of nodes that can be gradually reshaped and upscaled to 128x128x3\n",
        "\tn_nodes = 128 * 8 * 8 #8192 nodes\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((8, 8, 128)))\n",
        "\t# upsample to 16x16\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 32x32\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 64x64\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 128x128\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output layer 128x128x3\n",
        "\tmodel.add(Conv2D(3, (8,8), activation='tanh', padding='same')) #tanh goes from [-1,1]\n",
        "\treturn model\n",
        "\n",
        "test_gen = define_generator(100)\n",
        "print(test_gen.summary())\n",
        "plot_model(test_gen, to_file='generator_model.png', show_shapes=True)\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "test_gan = define_gan(test_gen, test_discr)\n",
        "print(test_gan.summary())\n",
        "plot_model(test_gan, to_file='combined_model.png', show_shapes=True)\n",
        "\n",
        "\n",
        "# Function to sample some random real images\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = ones((n_samples, 1)) # Class labels for real images are 1\n",
        "\treturn X, y\n",
        "\n",
        "# Function to generate random latent points\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator. \n",
        "\treturn x_input\n",
        "\n",
        "# Function to generate fake images using latent vectors\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples) #Generate latent points as input to the generator\n",
        "\tX = g_model.predict(x_input) #Use the generator to generate fake images\n",
        "\ty = zeros((n_samples, 1)) # Class labels for fake images are 0\n",
        "\treturn X, y\n",
        "\n",
        "# Function to save Plots after every n number of epochs\n",
        "def save_plot(examples, epoch, n=10):\n",
        "\t# scale images from [-1,1] to [0,1] so we can plot\n",
        "\texamples = (examples + 1) / 2.0\n",
        "\tfor i in range(n * n):\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(examples[i])\n",
        "\t# save plot to a file so we can view how generated images evolved over epochs\n",
        "\tfilename = 'saved_data_during_training/images/generated_plot_128x128_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()\n",
        "\n",
        "# Function to summarize performance periodically. \n",
        "# \n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\t# Fetch real images\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real images - get accuracy\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# Generate fake images\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake images - get accuracy\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# Print discriminate accuracies on ral and fake images. \n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save generated images periodically using the save_plot function\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model\n",
        "\tfilename = 'saved_data_during_training/models/generator_model_128x128_%03d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)\n",
        "\n",
        "# train the generator and discriminator by enumerating batches and epochs. \n",
        "#\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2) #Disc. trained on half batch real and half batch fake images\n",
        "\t#  enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches \n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t# Fetch random 'real' images\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# Train the discriminator using real images\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t\t# generate 'fake' images \n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# Train the discriminator using fake images\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\t# Generate latent vectors as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\t# Label generated (fake) mages as 1 to fool the discriminator \n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\t# Train the generator (via the discriminator's error)\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\t# Report disc. and gen losses. \n",
        "\t\t\tprint('Epoch>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\t\t# evaluate the model performance, sometimes\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
        "\n",
        "############################################\n",
        "\n",
        "#Now that we defined all necessary functions, let us load data and train the GAN.\n",
        "# Dataset from: https://susanqq.github.io/UTKFace/\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "n=20000 #Number of images to read from the directory. (For training)\n",
        "SIZE = 128 #Resize images to this size\n",
        "all_img_list = os.listdir('data/UTKFace/UTKFace/') #\n",
        "\n",
        "dataset_list = random.sample(all_img_list, n) #Get n random images from the directory\n",
        "\n",
        "#Read images, resize and capture into a numpy array\n",
        "dataset = []\n",
        "for img in dataset_list:\n",
        "    temp_img = cv2.imread(\"data/UTKFace/UTKFace/\" + img)\n",
        "    temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB) #opencv reads images as BGR so let us convert back to RGB\n",
        "    temp_img = Image.fromarray(temp_img)\n",
        "    temp_img = temp_img.resize((SIZE, SIZE)) #Resize\n",
        "    dataset.append(np.array(temp_img))   \n",
        "\n",
        "dataset = np.array(dataset) #Convert the list to numpy array\n",
        "\n",
        "#Rescale to [-1, 1] - remember that the generator uses tanh activation that goes from -1,1\n",
        "dataset = dataset.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "dataset = (dataset - 127.5) / 127.5\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator using our pre-defined function\n",
        "d_model = define_discriminator()\n",
        "# create the generator using our pre-defined function\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan  using our pre-defined function\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100)"
      ],
      "metadata": {
        "id": "SgFFK1u52lFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##rithmetic_with_GAN_latent_vectors_predict_V2.0.py"
      ],
      "metadata": {
        "id": "hbyAZ5in2lHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dataset from: Dataset from: https://susanqq.github.io/UTKFace/ \n",
        "Latent space is hard to interpret unless conditioned using many classes.​\n",
        "But, the latent space can be exploited using generated images.​\n",
        "Here is how...\n",
        "x Generate 10s of images using random latent vectors.​\n",
        "x Identify many images within each category of interest (e.g., smiling man, neutral man, etc. )​\n",
        "x Average the latent vectors for each category to get a mean representation in the latent space (for that category).​\n",
        "x Use these mean latent vectors to generate images with features of interest. ​\n",
        "This part of the code is used to generate 128x128x3 images (of faces) using a trained\n",
        "generator model. \n",
        "Alo, faces can be generated using two random latent vectors and interpolated in between.\n",
        "Finally, the features in the new images can be 'engineered' by doing simple arithmetic\n",
        "between vectors that are used to generate images. \n",
        "In summary, you can find the latent vectors for Smiling Man, neutral face man, \n",
        "and a baby with neutral face and then generate a smiling baby face by:\n",
        "    Smiling Man + Neutral Man - Neutral baby = Smiling Baby\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from tensorflow.keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "#####################################################################\n",
        "#Let us start by generating images using random latent vectors.\n",
        "#########################################################################\n",
        "# Function to generate random latent points\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator.\n",
        "\treturn z_input\n",
        "\n",
        "# Function to create a plot of generated images\n",
        "def plot_generated(examples, n):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(examples[i, :, :])\n",
        "\tplt.show()\n",
        "\n",
        "# load the saved model\n",
        "model = load_model('saved_data_during_training/models/generator_model_128x128_100.h5')\n",
        "# generate latent vectors to be used as input to the generator\n",
        "#Here, we are generating 25 latent vectors\n",
        "latent_points = generate_latent_points(100, 25)\n",
        "# generate images using the loaded generator model\n",
        "X  = model.predict(latent_points)\n",
        "# scale from [-1,1] to [0,1] for plotting\n",
        "X = (X + 1) / 2.0\n",
        "# plot the generated images. Let us do 5x5 plot as we generated 25 images\n",
        "plot_generated(X, 5)\n",
        "\n",
        "#####################################################################\n",
        "#Now, let us generate 2 latent vectors and interpolate between them.\n",
        "#Let us do linear interpolation although in reality the latent space is curved. \n",
        "#Interpolating between faces - Linear interpolation\n",
        "#################################################################\n",
        "\n",
        "from numpy import linspace\n",
        "\n",
        "# Function to generate random latent points\n",
        "#Same as defined above, re-defining for convenience. \n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        " \t# generate points in the latent space\n",
        " \tx_input = randn(latent_dim * n_samples)\n",
        " \tz_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator.\n",
        " \treturn z_input\n",
        "\n",
        "# Interpolation between two points in latent space\n",
        "def interpolate_points(p1, p2, n_steps=10):\n",
        " \t# interpolate between points (e.g., between 0 and 1 if you divde to 10 then you have 0.111, 0.222, etc.)\n",
        " \tratios = linspace(0, 1, num=n_steps)\n",
        " \t# linear interpolation of vectors based on the above interpolation ratios\n",
        " \tvectors = list()\n",
        " \tfor ratio in ratios:\n",
        "         v = (1.0 - ratio) * p1 + ratio * p2\n",
        "         vectors.append(v)\n",
        " \treturn asarray(vectors)\n",
        "\n",
        "# create a plot of generated images\n",
        "def plot_generated(examples, n):\n",
        " \t# plot images\n",
        " \tfor i in range(n):\n",
        "         plt.subplot(1, n, 1 + i)\n",
        "         plt.axis('off')\n",
        "         plt.imshow(examples[i, :, :])\n",
        " \tplt.show()\n",
        "\n",
        "# load the model, if you haven't already loaded it above. \n",
        "model = load_model('saved_data_during_training/models/generator_model_128x128_100.h5')\n",
        "# generate points in latent space\n",
        "#Let us generate 2 latent points between which we will interpolate\n",
        "pts = generate_latent_points(100, 2)\n",
        "# interpolate points in latent space\n",
        "interpolated = interpolate_points(pts[0], pts[1])\n",
        "# generate images using the interpolated latent points\n",
        "X = model.predict(interpolated)\n",
        "# scale from [-1,1] to [0,1] for plotting\n",
        "X = (X + 1) / 2.0\n",
        "# plot the result\n",
        "plot_generated(X, len(interpolated))\n",
        "\n",
        "################################################################\n",
        "#Now, let us perform arithmetic with latent points so we can generate faces\n",
        "#with features of interest. \n",
        "#To work with latent points we must first generate a bunch of faces and \n",
        "#save them along with their corresponding latent points. This can be used\n",
        "#to visually locate images of interest and thus identify the latent points.\n",
        "#For example, latent points corresponding to baby face or sun glasses, etc. \n",
        "###########################################################\n",
        "\n",
        "from numpy import mean, expand_dims\n",
        "# example of loading the generator model and generating images\n",
        "\n",
        "# Function to generate random latent points\n",
        "#Same as defined above, re-defining for convenience. \n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator.\n",
        "\treturn z_input\n",
        "\n",
        "# create a plot of generated images and save for easy visualization\n",
        "def plot_generated(examples, n):\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    for i in range(n * n):\n",
        "        plt.subplot(n, n, 1 + i)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(examples[i, :, :])\n",
        "    plt.savefig('generated_faces.png')\n",
        "    plt.close()\n",
        "\n",
        "# load the model, if you haven't already loaded it above\n",
        "model = load_model('saved_data_during_training/models/generator_model_128x128_100.h5')\n",
        "\n",
        "# generate points in latent space that we can use to generate some images\n",
        "#We then identify some images with our features of interest and locate thir corresponding latent vectors\n",
        "latent_points = generate_latent_points(100, 100)\n",
        "\n",
        "#Plot the latent points to see that they are spread around and we have no clue how to interpret them. \n",
        "import seaborn as sns\n",
        "sns.scatterplot(latent_points[0], latent_points[1])\n",
        "\n",
        "# generate images using the latent points. \n",
        "X  = model.predict(latent_points)\n",
        "# scale from [-1,1] to [0,1] for plotting\n",
        "X = (X + 1) / 2.0\n",
        "# plot and save generated images\n",
        "plot_generated(X, 10)\n",
        "\n",
        "#Now, identify images corresponding to a specific type.\n",
        "#e.g. all baby face images, smiling man images, \n",
        "# smiling man - neutral man + baby face = smiling baby\n",
        "\n",
        "# retrieve specific points\n",
        "#Now, identify images corresponding to a specific type.\n",
        "#Start counting from 1 as we are going to offset our image number later, by subtracting 1.\n",
        "#e.g. all baby face images, smiling man images, \n",
        "# smiling man - neutral man + baby face = smiling baby\n",
        "#OR try adult with glasses  - adult no glasses + baby no glasses\n",
        "\n",
        "#Identify a few images from classes of interest\n",
        "# smiling_man_ix = [1, 10, 16, 26, 27, 28]\n",
        "# neutral_man_ix = [16, 95, 63]\n",
        "# baby_ix = [13,26,28,93,94]\n",
        "adult_with_glasses = [3,39,40]\n",
        "adult_no_glasses = [4, 7, 8]\n",
        "#baby_no_glasses = [15,20]\n",
        "person_with_lipstick = [9, 10, 11, 31]\n",
        "#person_no_lipstick = [1, 4, 9, 15]\n",
        "\n",
        "#Reassign classes of interest to new variables... just to make it easy not\n",
        "# to change names all the time we get interested in new features. \n",
        "feature1_ix = adult_with_glasses\n",
        "feature2_ix = adult_no_glasses\n",
        "feature3_ix = person_with_lipstick\n",
        "\n",
        "# Function to average list of latent space vectors to get the mean for a given type\n",
        "def average_points(points, ix):\n",
        "\t# subtract 1 from image index so it matches the image from the array\n",
        "    # we are doing this as our array starts at 0 but we started counting at 1. \n",
        "\tzero_ix = [i-1 for i in ix]\n",
        "\t# retrieve required vectors corresponding to the selected images\n",
        "\tvectors = points[zero_ix]\n",
        "\t# average the vectors\n",
        "\tavg_vector = mean(vectors, axis=0)\n",
        "\t\n",
        "\treturn avg_vector\n",
        "\n",
        "# average vectors for each class\n",
        "feature1 = average_points(latent_points, feature1_ix)\n",
        "feature2 = average_points(latent_points, feature2_ix)\n",
        "feature3 = average_points(latent_points, feature3_ix)\n",
        "\n",
        "# Vector arithmetic....\n",
        "result_vector = feature1 - feature2 + feature3\n",
        "\n",
        "# generate image using the new calculated vector\n",
        "result_vector = expand_dims(result_vector, 0)\n",
        "result_image = model.predict(result_vector)\n",
        "\n",
        "# scale pixel values for plotting\n",
        "result_image = (result_image + 1) / 2.0\n",
        "plt.imshow(result_image[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GDP204nY2lJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mA_fL70o2lLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K6YGJV6d2lNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jg7UmNON2lPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jl8kGP9E2lSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EPNLI5PK2lU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Egw34_Wm2lXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8wCywz2c2lak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iArmonSv2ldf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j6bx0UdJ2lgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZAGNFaL02li1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cxxUmF4o2llu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VX2gD-B22loF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oPHaiv5u2lpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aCWWJUyF2lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qnXAWHxY2lui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E0CAipCq2lxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F2FsuNeE2l05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "50y6YfTT2l4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}